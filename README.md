**<h2>Sound Event Detection system for emergency related sounds in Polyphonic Urban Environments</h2>**
This project is a final year project for the computer engineering degree of the author, Daniel Carvalho. It implements a sound event detection system for emergency-related sounds in polyphonic urban environments. The system is designed to run on mobile Android devices in real-time.

The system utilizes a dual implementation of the Non-negative Matrix Factorization (NMF) machine learning method to separate and identify emergency-related sound events from a polyphonic urban environment. The NMF method is used to analyze the audio signals and extract features that can be used to classify different sound events. The system is fully simulated using Python, and the actual implementation uses Java and native C++ on an Android device.

**<h3>Implementation</h3>**
The system runs on an Android device making use of the Android SDK and NDK to construct, build, and run the system on the device.
The system is implemented in Java and C++, and the source code is available on this GitHub repository. To build the system, you will need to use the Android Studio IDE.

Once the system is built and installed on the device, you can run it and start detecting emergency-related sounds in the environment. The system will display the detected sound event on the screen via a live updating annotated timeline of detected sounds.

**<h3>Contributions</h3>**
The project is open-source, please fork away. Although contributions to this project are closed as is its further development.
This project is owned by the University of Pretoria.

**<h3>Acknowledgments</h3>**
I would like to thank my supervisor for their guidance and support throughout the project.
